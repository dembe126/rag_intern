import os                                                           # Standard Python-Modul f√ºr Betriebssystemfunktionen wie Dateipfad-Operationen
from langchain_community.document_loaders import PyMuPDFLoader        # Importiert den PDFLoader aus dem langchain_community-Paket, um PDF-Dokumente zu laden
from langchain.text_splitter import RecursiveCharacterTextSplitter  # Importiert den TextSplitter, um den Text bzw. Dokumente in kleinere Abschnitte (Chunks) zu unterteilen
from langchain.schema import Document                                # Importiert die Document-Klasse, um Dokumente zu erstellen und zu verwalten
from langchain_community.vectorstores import Chroma                 # Importiert die Chroma-Klasse, um Vektorspeicher zu erstellen und zu verwalten
from langchain_huggingface import HuggingFaceEmbeddings               # Importiert die HuggingFaceEmbeddings-Klasse, um Text in Vektoren umzuwandeln
from config import EMBEDDING_MODEL_NAME, DB_BASE_PATH               # Importiert Konfigurationen


'''
Diese Hilfsfunktion erstellt einen passenden Pfadnamen f√ºr die Vektordatenbank basierend auf dem Namen der PDF-Datei.
'''

def get_db_path(file_path, base_dir=DB_BASE_PATH):
    filename = os.path.basename(file_path)                  # Extrahiert den Dateinamen aus dem vollst√§ndigen Pfad (z.B. "dokument.pdf" aus "/ordner/dokument.pdf")
    name, _ = os.path.splitext(filename)                    # Trennt den Dateinamen vom Dateityp (z.B. "dokument" von ".pdf")
    return os.path.join(base_dir, name.lower())             # Gibt den vollst√§ndigen Pfad zur√ºck, wo die Vektordatenbank gespeichert werden soll (z.B. "./chroma_dbs/dokument")



'''
Diese Funktion l√§dt eine PDF-Datei und gibt den Inhalt als Liste von Dokumenten zur√ºck.
'''

def load_document(file_path):

    if not os.path.exists(file_path):                       # √úberpr√ºft, ob die Datei existiert
        print(f"Datei nicht gefunden: {file_path}")         # Wenn nicht, wird eine Fehlermeldung ausgegeben
        return []                                           # und eine leere Liste zur√ºckgegeben
    
    loader = PyMuPDFLoader(file_path)                         # Erstellt eine Instanz des PyPDFLoader mit dem angegebenen Dateipfad
    document = loader.load()                                # Ruft die load()-Methode auf, die das PDF liest ‚Üí jede Seite der PDF wird zu einem einzelnen Text-Dokument in einer Liste
    
    doc_name = os.path.splitext(os.path.basename(file_path))[0]     # Dokumentname ohne Pfad und Endung extrahieren
    
    
    for doc in document:                                            # Dokumentname zu jedem Seiten-Dokument hinzuf√ºgen
        doc.metadata['document_name'] = doc_name
    
    print (f"üìÑ Das Dokument hat {len(document)} Seiten")   # Gibt die Anzahl der der geladenen Seiten im Dokument aus
    return document                                         # Gibt die Liste der Dokumente (Seiten) zur√ºck.     



'''
L√§dt alle PDF-Dateien aus dem aktuellen Ordner.
'''


def load_all_pdfs_in_folder():
    pdf_files = [f for f in os.listdir(".") if f.lower().endswith(".pdf")]
    
    if not pdf_files:
        print("‚ùå Keine PDF-Dateien im aktuellen Ordner gefunden.")
        return []
    
    print(f"üìö {len(pdf_files)} PDF-Dateien gefunden:")
    for pdf in pdf_files:
        print(f"  - {pdf}")
    
    all_documents = []
    
    for pdf_file in pdf_files:
        print(f"\nüìñ Lade: {pdf_file}")
        documents = load_document(pdf_file)
        all_documents.extend(documents)
    
    print(f"\n‚úÖ Insgesamt {len(all_documents)} Seiten aus {len(pdf_files)} PDFs geladen")
    return all_documents



'''
Diese Funktion unterteilt die Dokumente in kleinere Textabschnitte (Chunks).
Beh√§lt sowohl Dokumentname als auch Seitenzahl in den Metadaten.
'''

def split_text(document_list):    
    text_splitter = RecursiveCharacterTextSplitter(             # wir erstellen eine Instanz des TextSplitters
        chunk_size=500,                                         # ein Dokument wird in Chunks von chunk_size Zeichen unterteilt
        chunk_overlap=150,                                       # Zwischen aufeinanderfolgenden Chunks gibt es eine √úberlappung von chunk_overlap Zeichen (f√ºr semantische √Ñhnlichkeit) 
        length_function=len,                                    # die L√§nge eines Chunks wird mit der Standard-L√§ngenfunktion gemessen
        add_start_index=True,                                   # f√ºgt den Startindex des Chunks als Metadaten hinzu
    )

    chunks = text_splitter.split_documents(document_list)       # wir teilen die Dokumente in Chunks auf, wobei jedes Dokument eine Seite repr√§sentiert
    
    print(f"‚úÇÔ∏è Das Dokument wurde in {len(chunks)} Chunks unterteilt.")     # Gibt die Anzahl der Chunks aus
    return chunks                                                          # Gibt die Liste der Chunks zur√ºck


'''
Erstellt eine neue Vektordatenbank aus den Chunks.
'''

def create_vectordb(chunks, db_path):
   
    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)  # Erstellt ein Embedding-Modell mit dem konfigurierten Modellnamen
    
    print(f"üõ†Ô∏è Neue Vektordatenbank wird erstellt: {db_path}")
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embedding_model,
        persist_directory=db_path
    )
    vectordb.persist()
    
    print(f"‚úÖ Vektordatenbank wurde gespeichert!")
    return vectordb



def main():
    """
    Hauptfunktion f√ºr das Preprocessing - verarbeitet alle PDFs im Ordner.
    """
    print("üîÑ Multi-PDF-Preprocessing startet...")
    
    # Datenbank-Pfad f√ºr alle PDFs
    db_path = "./chroma_dbs/all_documents"
    
    # Pr√ºfen ob Datenbank schon existiert
    if os.path.exists(db_path):
        print(f"‚ö†Ô∏è Datenbank existiert bereits: {db_path}")
        overwrite = input("M√∂chtest du sie √ºberschreiben? (j/n): ")
        if overwrite.lower() not in ["j", "ja", "y", "yes"]:
            print("‚ùå Preprocessing abgebrochen.")
            return
    
    # Alle PDFs laden
    print("üìö Alle PDFs werden geladen...")
    all_documents = load_all_pdfs_in_folder()
    
    if not all_documents:
        print("‚ùå Keine Dokumente geladen.")
        return
    
    # Text in Chunks aufteilen
    print("‚úÇÔ∏è Text wird in Chunks aufgeteilt...")
    chunks = split_text(all_documents)
    
    # Vektordatenbank erstellen
    print("üõ†Ô∏è Vektordatenbank wird erstellt...")
    vectordb = create_vectordb(chunks, db_path)
    
    print(f"üéâ Preprocessing abgeschlossen! Alle PDFs in einer Datenbank: {db_path}")


if __name__ == "__main__":
    main()